{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1e1YwuFtZd1t",
      "metadata": {
        "editable": true,
        "id": "1e1YwuFtZd1t",
        "tags": []
      },
      "source": [
        "# 第8章: ニューラルネット\n",
        "\n",
        "第7章で取り組んだポジネガ分類を題材として、ニューラルネットワークで分類モデルを実装する。なお、この章ではPyTorchやTensorFlow、JAXなどの深層学習フレームワークを活用せよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b03603ee-a54b-4b93-97a2-888f5e3feeff",
      "metadata": {
        "id": "b03603ee-a54b-4b93-97a2-888f5e3feeff"
      },
      "source": [
        "## 70. 単語埋め込みの読み込み\n",
        "\n",
        "事前学習済み単語埋め込みを活用し、$|V| \\times d_\\rm{emb}$ の単語埋め込み行列$\\pmb{E}$を作成せよ。ここで、$|V|$は単語埋め込みの語彙数、$d_\\rm{emb}$は単語埋め込みの次元数である。ただし、単語埋め込み行列の先頭の行ベクトル$\\pmb{E}_{0,:}$は、将来的にパディング（`<PAD>`）トークンの埋め込みベクトルとして用いたいので、ゼロベクトルとして予約せよ。ゆえに、$\\pmb{E}$の2行目以降に事前学習済み単語埋め込みを読み込むことになる。\n",
        "\n",
        "もし、Google Newsデータセットの[学習済み単語ベクトル](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing)（300万単語・フレーズ、300次元）を全て読み込んだ場合、$|V|=3000001, d_\\rm{emb}=300$になるはずである（ただ、300万単語の中には、殆ど用いられない稀な単語も含まれるので、語彙を削減した方がメモリの節約になる）。\n",
        "\n",
        "また、単語埋め込み行列の構築と同時に、単語埋め込み行列の各行のインデックス番号（トークンID）と、単語（トークン）への双方向の対応付けを保持せよ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "XgNj2B6QKS9i",
        "outputId": "bd03e2a9-e8d6-4ae0-e94c-6cc6305b09b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XgNj2B6QKS9i",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy"
      ],
      "metadata": {
        "id": "VDqeIr0iKj_L",
        "outputId": "a170ad78-43f1-4b1e-a295-11da7df5135b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VDqeIr0iKj_L",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api"
      ],
      "metadata": {
        "id": "3ZoPeAMwKoTf"
      },
      "id": "3ZoPeAMwKoTf",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Google Newsの学習済み単語ベクトルをダウンロード・ロード\n",
        "word2vec = api.load('word2vec-google-news-300')\n"
      ],
      "metadata": {
        "id": "HhU_68U0KwOS",
        "outputId": "8b11ef43-dca9-4f4e-9b12-7ba104588922",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HhU_68U0KwOS",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2id = {\"<PAD>\": 0}\n",
        "id2word = {0: \"<PAD>\"} #<PAD>を予約しておく\n",
        "\n",
        "for i, word in enumerate(word2vec.index_to_key):  # index_to_key は語彙のリスト\n",
        "    word2id[word] = i + 1  # 0は<PAD>だから+1\n",
        "    id2word[i + 1] = word"
      ],
      "metadata": {
        "id": "zQ8BHVpvDJp1"
      },
      "id": "zQ8BHVpvDJp1",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "74dTHailATvp"
      },
      "id": "74dTHailATvp",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word2vec) + 1  # <PAD>のために+1\n",
        "emb_dim = word2vec.vector_size\n",
        "\n",
        "embedding_tensor = torch.zeros((vocab_size, emb_dim), dtype=torch.float32)\n",
        "\n",
        "embedding_tensor[1:] = torch.from_numpy(word2vec.vectors)"
      ],
      "metadata": {
        "id": "TUIskwD2MbZJ"
      },
      "id": "TUIskwD2MbZJ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c45bc5ba-4a83-493a-a78e-04aa48f3db2e",
      "metadata": {
        "id": "c45bc5ba-4a83-493a-a78e-04aa48f3db2e"
      },
      "source": [
        "## 71. データセットの読み込み\n",
        "\n",
        "[General Language Understanding Evaluation (GLUE)](https://gluebenchmark.com/) ベンチマークで配布されている[Stanford Sentiment Treebank (SST)](https://dl.fbaipublicfiles.com/glue/data/SST-2.zip) をダウンロードし、訓練セット（train.tsv）と開発セット（dev.tsv）のテキストと極性ラベルと読み込み、全てのテキストをトークンID列に変換せよ。このとき、単語埋め込みの語彙でカバーされていない単語は無視し、トークン列に含めないことにせよ。また、テキストの全トークンが単語埋め込みの語彙に含まれておらず、空のトークン列となってしまう事例は、訓練セットおよび開発セットから削除せよ（このため、第7章の実験で得られた正解率と比較できなくなることに注意せよ）。\n",
        "\n",
        "事例の表現方法は任意でよいが、例えば\"contains no wit , only labored gags\"がネガティブに分類される事例は、次のような辞書オブジェクトで表現すればよい。\n",
        "\n",
        "```\n",
        "{'text': 'contains no wit , only labored gags',\n",
        " 'label': tensor([0.]),\n",
        " 'input_ids': tensor([ 3475,    87, 15888,    90, 27695, 42637])}\n",
        "```\n",
        "\n",
        "この例では、`text`はテキスト、`label`は分類ラベル（ポジティブなら`tensor([1.])`、ネガティブなら`tensor([0.])`）、`input_ids`はテキストのトークン列をID列で表現している。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/glue/data/SST-2.zip\n",
        "!unzip SST-2.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0yF3qKQhQ0LX",
        "outputId": "a57b1bd1-8679-4966-cac0-ec6f74a0c2b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0yF3qKQhQ0LX",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-19 03:00:14--  https://dl.fbaipublicfiles.com/glue/data/SST-2.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.155.173.80, 18.155.173.40, 18.155.173.116, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.155.173.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7439277 (7.1M) [application/zip]\n",
            "Saving to: ‘SST-2.zip’\n",
            "\n",
            "SST-2.zip           100%[===================>]   7.09M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-05-19 03:00:14 (48.5 MB/s) - ‘SST-2.zip’ saved [7439277/7439277]\n",
            "\n",
            "Archive:  SST-2.zip\n",
            "   creating: SST-2/\n",
            "  inflating: SST-2/dev.tsv           \n",
            "   creating: SST-2/original/\n",
            "  inflating: SST-2/original/README.txt  \n",
            "  inflating: SST-2/original/SOStr.txt  \n",
            "  inflating: SST-2/original/STree.txt  \n",
            "  inflating: SST-2/original/datasetSentences.txt  \n",
            "  inflating: SST-2/original/datasetSplit.txt  \n",
            "  inflating: SST-2/original/dictionary.txt  \n",
            "  inflating: SST-2/original/original_rt_snippets.txt  \n",
            "  inflating: SST-2/original/sentiment_labels.txt  \n",
            "  inflating: SST-2/test.tsv          \n",
            "  inflating: SST-2/train.tsv         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# データの読み込み\n",
        "train_df = pd.read_csv(\"SST-2/train.tsv\", sep='\\t', )\n",
        "dev_df = pd.read_csv(\"SST-2/dev.tsv\", sep='\\t', )\n"
      ],
      "metadata": {
        "id": "n80xl6PqQ9pz"
      },
      "id": "n80xl6PqQ9pz",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_ids(text, word2id):\n",
        "    ids = []\n",
        "    for word in text.split():\n",
        "        if word in word2id:\n",
        "            ids.append(word2id[word])\n",
        "    return ids"
      ],
      "metadata": {
        "id": "K2r8r6kwRhOR"
      },
      "id": "K2r8r6kwRhOR",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_processing(df, word2id):\n",
        "  data = []\n",
        "  for index, row in df.iterrows():\n",
        "    data_unit = {}\n",
        "    ids = text_to_ids(row[\"sentence\"], word2id)\n",
        "    if len(ids) > 0:\n",
        "      data_unit[\"text\"] = row[\"sentence\"]\n",
        "      data_unit[\"label\"] = torch.tensor([row[\"label\"]], dtype=torch.float32)\n",
        "      data_unit[\"input_ids\"] = torch.tensor(ids, dtype=torch.long)\n",
        "      data.append(data_unit)\n",
        "  return data\n"
      ],
      "metadata": {
        "id": "9MReYfu1VwSz"
      },
      "id": "9MReYfu1VwSz",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pre_processing(train_df, word2id)\n",
        "dev_data = pre_processing(dev_df, word2id)"
      ],
      "metadata": {
        "id": "1s_6i-RQV7GE"
      },
      "id": "1s_6i-RQV7GE",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:5]"
      ],
      "metadata": {
        "id": "vxjEDHXAb0AS",
        "outputId": "c65b15a0-0d85-4933-fdf0-bdd5958bcf14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vxjEDHXAb0AS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'hide new secretions from the parental units ',\n",
              "  'label': tensor([0.]),\n",
              "  'input_ids': tensor([  5785,     66, 113845,     18,     12,  15095,   1594])},\n",
              " {'text': 'contains no wit , only labored gags ',\n",
              "  'label': tensor([0.]),\n",
              "  'input_ids': tensor([ 3475,    87, 15888,    90, 27695, 42637])},\n",
              " {'text': 'that loves its characters and communicates something rather beautiful about human nature ',\n",
              "  'label': tensor([1.]),\n",
              "  'input_ids': tensor([    4,  5053,    45,  3305, 31647,   348,   904,  2815,    47,  1276,\n",
              "           1964])},\n",
              " {'text': 'remains utterly satisfied to remain the same throughout ',\n",
              "  'label': tensor([0.]),\n",
              "  'input_ids': tensor([  987, 14528,  4941,   873,    12,   208,   898])},\n",
              " {'text': 'on the worst revenge-of-the-nerds clichés the filmmakers could dredge up ',\n",
              "  'label': tensor([0.]),\n",
              "  'input_ids': tensor([    6,    12,  1445, 43789,    12, 10946,    76, 41349,    42])}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29dfe527-a08c-48fa-b9b4-0acebea36bca",
      "metadata": {
        "id": "29dfe527-a08c-48fa-b9b4-0acebea36bca"
      },
      "source": [
        "## 72. Bag of wordsモデルの構築\n",
        "\n",
        "単語埋め込みの平均ベクトルでテキストの特徴ベクトルを表現し、重みベクトルとの内積でポジティブ及びネガティブを分類するニューラルネットワーク（ロジスティック回帰モデル）を設計せよ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def input_ids2mean_feature(input_ids, embedding_tensor):\n",
        "    selected_vectors = embedding_tensor[input_ids]\n",
        "    mean_vector = torch.mean(selected_vectors, dim=0)\n",
        "\n",
        "    return mean_vector"
      ],
      "metadata": {
        "id": "KmYJUADM5O46"
      },
      "id": "KmYJUADM5O46",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex_mean = input_ids2mean_feature(train_data[0][\"input_ids\"], embedding_tensor)\n",
        "ex_mean.shape"
      ],
      "metadata": {
        "id": "czlwim7bddqF",
        "outputId": "f7f26ddd-a8e4-49e8-cbe5-43afc5f1c2df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "czlwim7bddqF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([300])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LogisticRegression(nn.Module): #ロジスティック回帰の設計\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = self.linear(x)\n",
        "        h2 = torch.sigmoid(h1)\n",
        "        return h2"
      ],
      "metadata": {
        "id": "dbLR1IWwwIfB"
      },
      "id": "dbLR1IWwwIfB",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "72385c44-ceab-4d62-a4df-3023e15a37e2",
      "metadata": {
        "id": "72385c44-ceab-4d62-a4df-3023e15a37e2"
      },
      "source": [
        "## 73. モデルの学習\n",
        "\n",
        "問題72で設計したモデルの重みベクトルを訓練セット上で学習せよ。ただし、学習中は単語埋め込み行列の値を固定せよ（単語埋め込み行列のファインチューニングは行わない）。また、学習時に損失値を表示するなど、学習の進捗状況をモニタリングできるようにせよ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(emb_dim, 1)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data_unit in train_data:\n",
        "        # 特徴ベクトルの計算\n",
        "        feature_vector = input_ids2mean_feature(data_unit[\"input_ids\"], embedding_tensor)\n",
        "\n",
        "        #modelが予測する\n",
        "        output = model(feature_vector)\n",
        "\n",
        "        loss = criterion(output, data_unit[\"label\"])\n",
        "\n",
        "        # バックプロパゲーションとパラメータ更新\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_data):.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw8iesBRzoE-",
        "outputId": "7a68d986-f514-4aab-f645-cb79e7ffd215"
      },
      "id": "gw8iesBRzoE-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.4024\n",
            "Epoch 2/10, Loss: 0.3725\n",
            "Epoch 3/10, Loss: 0.3701\n",
            "Epoch 4/10, Loss: 0.3692\n",
            "Epoch 5/10, Loss: 0.3688\n",
            "Epoch 6/10, Loss: 0.3686\n",
            "Epoch 7/10, Loss: 0.3685\n",
            "Epoch 8/10, Loss: 0.3684\n",
            "Epoch 9/10, Loss: 0.3684\n",
            "Epoch 10/10, Loss: 0.3683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26b25b5b-0ed2-4bf0-8350-601812eb057f",
      "metadata": {
        "id": "26b25b5b-0ed2-4bf0-8350-601812eb057f"
      },
      "source": [
        "## 74. モデルの評価\n",
        "\n",
        "問題73で学習したモデルの開発セットにおける正解率を求めよ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy(model, dev_data, embedding_tensor):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data_unit in dev_data:\n",
        "            feature_vector = input_ids2mean_feature(data_unit[\"input_ids\"], embedding_tensor)\n",
        "\n",
        "            output = model(feature_vector)\n",
        "\n",
        "            pred = (output >= 0.5).float()\n",
        "\n",
        "            correct += (pred == data_unit[\"label\"]).sum().item()\n",
        "            total += 1\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "y4hh6DDt7z2_"
      },
      "id": "y4hh6DDt7z2_",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "O08V9g0mcJwe",
      "metadata": {
        "id": "O08V9g0mcJwe"
      },
      "source": [
        "## 75. パディング\n",
        "\n",
        "複数の事例が与えられたとき、これらをまとめて一つのテンソル・オブジェクトで表現する関数`collate`を実装せよ。与えられた複数の事例のトークン列の長さが異なるときは、トークン列の長さが最も長いものに揃え、0番のトークンIDでパディングをせよ。さらに、トークン列の長さが長いものから順に、事例を並び替えよ。\n",
        "\n",
        "例えば、訓練データセットの冒頭の4事例が次のように表されているとき、\n",
        "\n",
        "```\n",
        "[{'text': 'hide new secretions from the parental units',\n",
        "  'label': tensor([0.]),\n",
        "  'input_ids': tensor([  5785,     66, 113845,     18,     12,  15095,   1594])},\n",
        " {'text': 'contains no wit , only labored gags',\n",
        "  'label': tensor([0.]),\n",
        "  'input_ids': tensor([ 3475,    87, 15888,    90, 27695, 42637])},\n",
        " {'text': 'that loves its characters and communicates something rather beautiful about human nature',\n",
        "  'label': tensor([1.]),\n",
        "  'input_ids': tensor([    4,  5053,    45,  3305, 31647,   348,   904,  2815,    47,  1276,  1964])},\n",
        " {'text': 'remains utterly satisfied to remain the same throughout',\n",
        "  'label': tensor([0.]),\n",
        "  'input_ids': tensor([  987, 14528,  4941,   873,    12,   208,   898])}]\n",
        "```\n",
        "\n",
        "`collate`関数を通した結果は以下のようになることが想定される。\n",
        "\n",
        "```\n",
        "{'input_ids': tensor([\n",
        "    [     4,   5053,     45,   3305,  31647,    348,    904,   2815,     47,   1276,   1964],\n",
        "    [  5785,     66, 113845,     18,     12,  15095,   1594,      0,      0,      0,      0],\n",
        "    [   987,  14528,   4941,    873,     12,    208,    898,      0,      0,      0,      0],\n",
        "    [  3475,     87,  15888,     90,  27695,  42637,      0,      0,      0,      0,      0]]),\n",
        " 'label': tensor([\n",
        "    [1.],\n",
        "    [0.],\n",
        "    [0.],\n",
        "    [0.]])}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate(batch):\n",
        "    # トークン長が長い順にソート\n",
        "    batch = sorted(batch, key=lambda x: len(x[\"input_ids\"]), reverse=True)\n",
        "\n",
        "    max_len = len(batch[0][\"input_ids\"])  #sortしたあとだから，0番目がmax\n",
        "\n",
        "    padded_input_ids = []\n",
        "    labels = []\n",
        "\n",
        "    for data_unit in batch:\n",
        "        input_ids = data_unit[\"input_ids\"]\n",
        "        label = data_unit[\"label\"]\n",
        "\n",
        "        # パディングする数\n",
        "        pad_len = max_len - len(input_ids)\n",
        "        padded = torch.cat([input_ids, torch.zeros(pad_len, dtype=torch.long)])  #pad_lenの数だけ下のinput_idsに0を連結する\n",
        "\n",
        "        padded_input_ids.append(padded) #この時はshape: (max_len)のテンソルのリスト\n",
        "        labels.append(label)\n",
        "\n",
        "    # バッチテンソルに変換\n",
        "    padded_input_ids = torch.stack(padded_input_ids)  # shape: (batch_size, max_len)　torch.stack使えばリストの中にテンソルが入っている状態のものを一つのテンソルにー\n",
        "    labels = torch.stack(labels)  # shape: (batch_size, 1)\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": padded_input_ids,\n",
        "        \"label\": labels\n",
        "    }\n"
      ],
      "metadata": {
        "id": "i_t__bu6p1eu"
      },
      "id": "i_t__bu6p1eu",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex_padding = collate(train_data[:5])\n",
        "ex_padding"
      ],
      "metadata": {
        "id": "cxTEseoZsCp3",
        "outputId": "6c7373be-b5ec-4cdd-a350-674530dd6ad0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cxTEseoZsCp3",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[     4,   5053,     45,   3305,  31647,    348,    904,   2815,     47,\n",
              "            1276,   1964],\n",
              "         [     6,     12,   1445,  43789,     12,  10946,     76,  41349,     42,\n",
              "               0,      0],\n",
              "         [  5785,     66, 113845,     18,     12,  15095,   1594,      0,      0,\n",
              "               0,      0],\n",
              "         [   987,  14528,   4941,    873,     12,    208,    898,      0,      0,\n",
              "               0,      0],\n",
              "         [  3475,     87,  15888,     90,  27695,  42637,      0,      0,      0,\n",
              "               0,      0]]),\n",
              " 'label': tensor([[1.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]])}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9NzvuZ-5ebDU",
      "metadata": {
        "id": "9NzvuZ-5ebDU"
      },
      "source": [
        "## 76. ミニバッチ学習\n",
        "\n",
        "問題75のパディングの処理を活用して、ミニバッチでモデルを学習せよ。また、学習したモデルの開発セットにおける正解率を求めよ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx]"
      ],
      "metadata": {
        "id": "vocnGSO9rZCt"
      },
      "id": "vocnGSO9rZCt",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MyDataset(train_data)\n",
        "train_dataset.__getitem__(0) #確認してみた"
      ],
      "metadata": {
        "id": "GjobfLJZsOF2",
        "outputId": "075eb16b-7474-4cef-abc3-9407a23b9560",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GjobfLJZsOF2",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'hide new secretions from the parental units ',\n",
              " 'label': tensor([0.]),\n",
              " 'input_ids': tensor([  5785,     66, 113845,     18,     12,  15095,   1594])}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate)"
      ],
      "metadata": {
        "id": "rU0fRhG1tF-w"
      },
      "id": "rU0fRhG1tF-w",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for data in train_dataloader:\n",
        "    print(data)\n",
        "    i = i+1\n",
        "    if i > 3:\n",
        "      break #確認してみた\n"
      ],
      "metadata": {
        "id": "mXoVEDEYtLIo",
        "outputId": "28f65226-7501-412b-f791-e694306a66df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mXoVEDEYtLIo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[     3,     53,     45,   1023,    451,    649,    112,    677,    184,\n",
            "         198991,    179,     42,    121,    139,  10012,     30,  22480],\n",
            "        [     5,   2441,      9,  90055,   3463, 100498,   3305,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0],\n",
            "        [    77,  55120, 198991,    143,     16,    102,     40,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0],\n",
            "        [     2,   1192,  36265,   5908,   6161,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0],\n",
            "        [  2377,   3036,      6,     45,    413,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0],\n",
            "        [    12,   3913,      5,  27154,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0],\n",
            "        [ 51846,   6227,   7014,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0],\n",
            "        [  5629,     34,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0]]), 'label': tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.]])}\n",
            "{'input_ids': tensor([[    76,     22,   1832,    412,   2313,   7121,   2438,      2,  60721,\n",
            "          84901,   4189,     42,   1794,   5037,   1006,   1027,  53761,  75884],\n",
            "        [    16,     84,  16528,   2454,    637,    234,     17,     84,     12,\n",
            "            740,   4018,     76,    205,     40,   3377,   6572,   4384,      0],\n",
            "        [    39,    191,    469,     12,   4124,    100,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0],\n",
            "        [    44,    130,    608,  80687,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0],\n",
            "        [    12,    693,      5,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0],\n",
            "        [  1269, 343005,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0],\n",
            "        [ 19477,  18452,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0],\n",
            "        [   155,  63055,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0]]), 'label': tensor([[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.]])}\n",
            "{'input_ids': tensor([[    44,    239,    310,     12,   6139,    984,     12,  33471,   2446,\n",
            "            789,    196],\n",
            "        [   110,    308,    624,     12,  11833,   1169,  21358,     14,      0,\n",
            "              0,      0],\n",
            "        [ 53761,  45937,   9427,      5,     28,    503,      3, 228903,      0,\n",
            "              0,      0],\n",
            "        [ 20322,     19,    466, 105063,   2354,   2214,      0,      0,      0,\n",
            "              0,      0],\n",
            "        [  1194,      5,    906,   1083,  80602,      0,      0,      0,      0,\n",
            "              0,      0],\n",
            "        [     9,     12,  16789,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0],\n",
            "        [   949,    476,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0],\n",
            "        [  4582,   2815,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0]]), 'label': tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]])}\n",
            "{'input_ids': tensor([[    16,    639,    123,    329,   1535, 110952,   2102,   1122,   1501,\n",
            "             15,  28611,  23518,     15,     12,   2913,   2853],\n",
            "        [  1003,    399,     12,  46155,     12,    208,    133,     93,      9,\n",
            "            982,   7559,   7626,   1652,  14440,      0,      0],\n",
            "        [   852, 133311,  22421,   2472,     70,     12,   2854,   1625,     72,\n",
            "            414,  23164,      0,      0,      0,      0,      0],\n",
            "        [184286, 802418,  37976,     20,   8822,  81458,     33,   1574,   3417,\n",
            "           2354,   2214,      0,      0,      0,      0,      0],\n",
            "        [   360,    693,     49,     12,  51093,   3376,  11639,   7375,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0],\n",
            "        [    20,   3425,  60482,     17,     36,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0],\n",
            "        [ 27686,   3948,    904,     61,   5262,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0],\n",
            "        [   921,    749,  18912,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0]]), 'label': tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_batch_learning = LogisticRegression(emb_dim, 1)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model_with_batch_learning.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_with_batch_learning.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "\n",
        "      input_ids_batch = batch['input_ids'] #shape: (B, L)\n",
        "      label_batch = batch['label'].float().squeeze(1) #shape: (B,)\n",
        "\n",
        "      # 特徴量の平均ベクトルをバッチ単位で計算\n",
        "        # embedding_tensor: shape (Vocab_size, emb_dim)\n",
        "        # input_ids_batch: shape (B, L)\n",
        "      embedded = embedding_tensor[input_ids_batch]  # shape: (B, L, D)\n",
        "      mean_vectors = embedded.mean(dim=1)           # shape: (B, D)\n",
        "\n",
        "      outputs = model_with_batch_learning(mean_vectors).squeeze(1)      # shape: (B,)\n",
        "\n",
        "      loss = criterion(outputs, label_batch)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_dataloader):.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "iK4D2nYuwNsI",
        "outputId": "2c0ece57-5c6b-43c6-af4f-63e9e46851cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "iK4D2nYuwNsI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.5430\n",
            "Epoch 2/10, Loss: 0.4486\n",
            "Epoch 3/10, Loss: 0.4240\n",
            "Epoch 4/10, Loss: 0.4132\n",
            "Epoch 5/10, Loss: 0.4059\n",
            "Epoch 6/10, Loss: 0.4013\n",
            "Epoch 7/10, Loss: 0.3973\n",
            "Epoch 8/10, Loss: 0.3960\n",
            "Epoch 9/10, Loss: 0.3950\n",
            "Epoch 10/10, Loss: 0.3945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluate_accuracy(model_with_batch_learning, dev_data, embedding_tensor)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "FuWWyzyH6CRH",
        "outputId": "9329cd67-1598-40d4-f6cf-1e824c2245a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FuWWyzyH6CRH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 80.28%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RUbjivUTejxn",
      "metadata": {
        "id": "RUbjivUTejxn"
      },
      "source": [
        "## 77. GPU上での学習\n",
        "\n",
        "問題76のモデル学習をGPU上で実行せよ。また、学習したモデルの開発セットにおける正解率を求めよ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model_with_batch_learning = LogisticRegression(emb_dim, 1).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model_with_batch_learning.parameters(), lr=0.001)\n",
        "\n",
        "embedding_tensor = embedding_tensor.to(device)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_with_batch_learning.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "\n",
        "        input_ids_batch = batch['input_ids'].to(device)        # shape: (B, L)\n",
        "        label_batch = batch['label'].float().squeeze(1).to(device)  # shape: (B,)\n",
        "\n",
        "        # embedding_tensor: shape (Vocab_size, emb_dim)\n",
        "        # input_ids_batch: shape (B, L)\n",
        "        embedded = embedding_tensor[input_ids_batch]  # shape: (B, L, D)\n",
        "        mean_vectors = embedded.mean(dim=1)           # shape: (B, D)\n",
        "\n",
        "        outputs = model_with_batch_learning(mean_vectors).squeeze(1)  # shape: (B,)\n",
        "\n",
        "        loss = criterion(outputs, label_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_dataloader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfKoazzMDoYE",
        "outputId": "c482a3ef-74f1-4695-e534-98fe4774d7d0"
      },
      "id": "hfKoazzMDoYE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1/10, Loss: 0.5426\n",
            "Epoch 2/10, Loss: 0.4494\n",
            "Epoch 3/10, Loss: 0.4243\n",
            "Epoch 4/10, Loss: 0.4132\n",
            "Epoch 5/10, Loss: 0.4057\n",
            "Epoch 6/10, Loss: 0.4005\n",
            "Epoch 7/10, Loss: 0.3975\n",
            "Epoch 8/10, Loss: 0.3955\n",
            "Epoch 9/10, Loss: 0.3941\n",
            "Epoch 10/10, Loss: 0.3924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_evaluate_accuracy(model, dev_data, embedding_tensor, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    model.to(device)\n",
        "    embedding_tensor = embedding_tensor.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data_unit in dev_data:\n",
        "            input_ids = data_unit[\"input_ids\"].to(device)\n",
        "            label = data_unit[\"label\"].to(device)\n",
        "\n",
        "            feature_vector = input_ids2mean_feature(input_ids, embedding_tensor)\n",
        "\n",
        "            output = model(feature_vector)\n",
        "\n",
        "            pred = (output >= 0.5).float()\n",
        "\n",
        "            correct += (pred == label).sum().item()\n",
        "            total += 1\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "3Gwiv4ieHu4F"
      },
      "id": "3Gwiv4ieHu4F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = new_evaluate_accuracy(model_with_batch_learning, dev_data, embedding_tensor, device)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "MGZAlFX8HMos",
        "outputId": "d456b0e6-09d5-4f46-8455-83591273e3e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MGZAlFX8HMos",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 80.39%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZUY1PsD-eplq",
      "metadata": {
        "id": "ZUY1PsD-eplq"
      },
      "source": [
        "## 78. 単語埋め込みのファインチューニング\n",
        "\n",
        "問題77の学習において、単語埋め込みのパラメータも同時に更新するファインチューニングを導入せよ。また、学習したモデルの開発セットにおける正解率を求めよ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "embedding_layer = nn.Embedding.from_pretrained(embedding_tensor, freeze=False).to(device)\n",
        "model_with_batch_learning_gpu = LogisticRegression(emb_dim, 1).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(\n",
        "    list(model_with_batch_learning_gpu.parameters()) + list(embedding_layer.parameters()),\n",
        "    lr=0.001\n",
        ")\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_with_batch_learning_gpu.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "        input_ids_batch = batch['input_ids'].to(device)\n",
        "        label_batch = batch['label'].float().squeeze(1).to(device)\n",
        "\n",
        "        embedded = embedding_layer(input_ids_batch)  # shape: (B, L, D)\n",
        "        mean_vectors = embedded.mean(dim=1)          # shape: (B, D)\n",
        "\n",
        "        outputs = model_with_batch_learning_gpu(mean_vectors).squeeze(1)\n",
        "\n",
        "        loss = criterion(outputs, label_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_dataloader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "28io_DPhEsuw",
        "outputId": "4d51f248-6156-4ae8-e62e-6f7d08e14d1d"
      },
      "id": "28io_DPhEsuw",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 3.35 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.17 GiB is free. Process 13234 has 13.57 GiB memory in use. Of the allocated memory 13.43 GiB is allocated by PyTorch, and 5.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-351f4dc2fc3e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    242\u001b[0m             )\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    877\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    701\u001b[0m                 \u001b[0mexp_avg_sq_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_sqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_max_exp_avg_sqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                 \u001b[0mexp_avg_sq_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_sqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_exp_avg_sqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_div_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq_sqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.35 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.17 GiB is free. Process 13234 has 13.57 GiB memory in use. Of the allocated memory 13.43 GiB is allocated by PyTorch, and 5.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "単語埋め込みベクトルも学習させようとすると，メモリに乗っかりきらないっぽい(無料の限界)"
      ],
      "metadata": {
        "id": "PwoBIWEbIIhV"
      },
      "id": "PwoBIWEbIIhV"
    },
    {
      "cell_type": "markdown",
      "id": "jVAdWIq0evKR",
      "metadata": {
        "id": "jVAdWIq0evKR"
      },
      "source": [
        "## 79. アーキテクチャの変更\n",
        "\n",
        "ニューラルネットワークのアーキテクチャを自由に変更し、モデルを学習せよ。また、学習したモデルの開発セットにおける正解率を求めよ。例えば、テキストの特徴ベクトル（単語埋め込みの平均ベクトル）に対して多層のニューラルネットワークを通したり、畳み込みニューラルネットワーク（CNN; Convolutional Neural Network）や再帰型ニューラルネットワーク（RNN; Recurrent Neural Network）などのモデルの学習に挑戦するとよい。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MLP(nn.Module):  # MLPモデルの定義\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)  # 入力層→隠れ層\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)  # 隠れ層→出力層\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = F.relu(self.fc1(x))       # ReLU活性化関数\n",
        "        h2 = torch.sigmoid(self.fc2(h1))  # 出力層はシグモイド\n",
        "        return h2\n"
      ],
      "metadata": {
        "id": "vc8MlC3rI15v"
      },
      "id": "vc8MlC3rI15v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "mlp = MLP(emb_dim,64, 1).to(device) #hidden_dimを64にした\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.001)\n",
        "\n",
        "embedding_tensor = embedding_tensor.to(device)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    mlp.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "\n",
        "        input_ids_batch = batch['input_ids'].to(device)        # shape: (B, L)\n",
        "        label_batch = batch['label'].float().squeeze(1).to(device)  # shape: (B,)\n",
        "\n",
        "        # embedding_tensor: shape (Vocab_size, emb_dim)\n",
        "        # input_ids_batch: shape (B, L)\n",
        "        embedded = embedding_tensor[input_ids_batch]  # shape: (B, L, D)\n",
        "        mean_vectors = embedded.mean(dim=1)           # shape: (B, D)\n",
        "\n",
        "        outputs = mlp(mean_vectors).squeeze(1)  # shape: (B,)\n",
        "\n",
        "        loss = criterion(outputs, label_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_dataloader):.4f}\")\n"
      ],
      "metadata": {
        "id": "OlpszsU2JM9Q",
        "outputId": "722e11ee-153c-48da-f71c-424fd89cce0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OlpszsU2JM9Q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1/10, Loss: 0.3831\n",
            "Epoch 2/10, Loss: 0.3357\n",
            "Epoch 3/10, Loss: 0.3219\n",
            "Epoch 4/10, Loss: 0.3080\n",
            "Epoch 5/10, Loss: 0.2952\n",
            "Epoch 6/10, Loss: 0.2811\n",
            "Epoch 7/10, Loss: 0.2685\n",
            "Epoch 8/10, Loss: 0.2572\n",
            "Epoch 9/10, Loss: 0.2452\n",
            "Epoch 10/10, Loss: 0.2346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = new_evaluate_accuracy(mlp, dev_data, embedding_tensor, device)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "CHnsPB3HJuFz",
        "outputId": "26450018-6508-45d6-8ef2-ae5b38624b9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CHnsPB3HJuFz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 79.13%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "過学習か"
      ],
      "metadata": {
        "id": "FSQ6sg5PKgSa"
      },
      "id": "FSQ6sg5PKgSa"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}